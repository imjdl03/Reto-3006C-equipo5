{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2f3fdf",
   "metadata": {},
   "source": [
    "# Pruebas de modelación\n",
    "Durante este proceso se pondrán a prueba distintos modelos de Machine Learning de entre los cuales se encuentran: Regresión Logistica, Naive Bayes, K-Nearest, Support Vector Machines, Arboles de Decisión y Random Forest. El objetivo de estas pruebas es evaluar que modelo presenta mejores resultados acorde a la problematica abordada para la predicción de la la muerte o supervivencia de el set de datos de el Titanic descrito en reportes anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7b0f2",
   "metadata": {},
   "source": [
    "### Importando librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T00:57:15.273681900Z",
     "start_time": "2023-08-28T00:57:15.257775800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf356cd4",
   "metadata": {},
   "source": [
    "### Leyendo Set De Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8255e3580eb4d715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T00:55:02.683698800Z",
     "start_time": "2023-08-28T00:55:02.675692300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/Github/Reto-3006C-equipo5/retro/M4_Reto/Data/train_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ed343",
   "metadata": {},
   "source": [
    "### Separación de datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae39ca6093908eb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T00:55:02.858546Z",
     "start_time": "2023-08-28T00:55:02.838527400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((708, 15), (178, 15))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c2507",
   "metadata": {},
   "source": [
    "### Pruebas de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbbdc727e579352",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7769f58273ef014f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:01:26.983034400Z",
     "start_time": "2023-08-28T01:01:26.830895100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.764\n",
      "Random Forest: 0.986\n"
     ]
    }
   ],
   "source": [
    "# Haremos una prueba con un random forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, y_pred)\n",
    "training_accuracy = accuracy_score(y_train, rf.predict(X_train))\n",
    "\n",
    "print('Random Forest: {:.3f}'.format(testing_accuracy))\n",
    "print('Random Forest: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422be624b417e2b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Al ejecutar un modelo Random Forest en nuestros datos de prueba y entrenamiento, observamos que el rendimiento en los datos de entrenamiento es excepcionalmente alto (aproximadamente 98.6%), mientras que en los datos de prueba es significativamente menor (alrededor del 76.4%). Esta discrepancia entre el rendimiento en entrenamiento y prueba sugiere la presencia de overfitting. En otras palabras, el modelo está aprendiendo demasiado los detalles específicos de los datos de entrenamiento y tiene dificultades para generalizar adecuadamente a nuevos datos. Para abordar este problema, exploraremos el uso de modelos con regularización en un intento de mejorar la capacidad de generalización y obtener resultados más confiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49b3b24285e92041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:17:10.249057600Z",
     "start_time": "2023-08-28T01:16:28.965592600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Random Forest: 0.809\n",
      "Random Forest: 0.893\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],      \n",
    "    'max_depth': [None, 10, 20, 30],      \n",
    "    'min_samples_split': [2, 5, 10],      \n",
    "    'min_samples_leaf': [1, 2, 4],        \n",
    "    'bootstrap': [True, False],          \n",
    "    'criterion': ['gini', 'entropy'] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',       \n",
    "    cv=5,                     \n",
    "    verbose=1,               \n",
    "    n_jobs=-1                   \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, best_clf.predict(X_test))\n",
    "training_accuracy = accuracy_score(y_train, best_clf.predict(X_train))\n",
    "\n",
    "print('Random Forest: {:.3f}'.format(testing_accuracy))\n",
    "print('Random Forest: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbb1b44c1f4104",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Tras aplicar la optimización de parámetros en nuestro modelo Random Forest, observamos una mejora significativa en el rendimiento. Ahora, en los datos de prueba, obtenemos un accuracy del aproximadamente 80.9%, en comparación con el 76.4% obtenido anteriormente sin optimización. En los datos de entrenamiento, el rendimiento también ha mejorado, alcanzando un accuracy de alrededor del 89.3%.\n",
    "\n",
    "Sin embargo, a pesar de estas mejoras, todavía enfrentamos un desafío importante: el modelo sigue mostrando signos de overfitting. La discrepancia entre el rendimiento en entrenamiento y prueba sugiere que el modelo aún tiene dificultades para generalizar completamente a nuevos datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27f809003b8c5fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68bfd7c717bc0529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:23:51.345997300Z",
     "start_time": "2023-08-28T01:23:51.316977400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.775\n",
      "Logistic Regression: 0.847\n"
     ]
    }
   ],
   "source": [
    "# Haremos una prueba con un logistic regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, y_pred)\n",
    "training_accuracy = accuracy_score(y_train, lr.predict(X_train))\n",
    "\n",
    "print('Logistic Regression: {:.3f}'.format(testing_accuracy))\n",
    "print('Logistic Regression: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4bc0070bde4a0d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Al aplicar un modelo de regresión logística a nuestros datos, observamos un rendimiento del aproximadamente 84.7% en los datos de entrenamiento, mientras que en los datos de prueba obtenemos un accuracy de alrededor del 77.5%. Esta discrepancia entre el rendimiento en entrenamiento y prueba sugiere una vez más la presencia de overfitting, donde el modelo está aprendiendo demasiado los detalles específicos de los datos de entrenamiento y tiene dificultades para generalizar a nuevos datos.\n",
    "\n",
    "Dada esta observación, planeamos abordar el overfitting mediante la aplicación de modelos de regresión logística con regularización. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a06e4fb172b0a634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:23:23.653564400Z",
     "start_time": "2023-08-28T01:21:41.707374600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n",
      "{'C': 2, 'l1_ratio': 0.5, 'max_iter': 5000, 'penalty': 'elasticnet'}\n",
      "Logistic Regression: 0.775\n",
      "Logistic Regression: 0.833\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='saga')\n",
    "\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],     \n",
    "    'C': [0.001, 0.01, 0.1, 1, 2, 5, 10, 100],          \n",
    "    'l1_ratio': [0, 0.1, 0.2, 0.5, 1],\n",
    "    'max_iter': [500, 1000, 2000, 3000, 5000, 10000]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',         \n",
    "    cv=5,                       \n",
    "    verbose=1,                 \n",
    "    n_jobs=-1                   \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, best_clf.predict(X_test))\n",
    "training_accuracy = accuracy_score(y_train, best_clf.predict(X_train))\n",
    "\n",
    "print('Logistic Regression: {:.3f}'.format(testing_accuracy))\n",
    "print('Logistic Regression: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7e5fd97a44c48",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Después de aplicar la regularización y optimizar los parámetros en nuestro modelo de regresión logística, observamos mejoras notables en el rendimiento. En los datos de prueba, ahora obtenemos un accuracy del aproximadamente 83.3%, en comparación con el 77.5% obtenido anteriormente sin regularización. En los datos de entrenamiento, el rendimiento también ha mejorado, alcanzando un accuracy de alrededor del 83.3%.\n",
    "\n",
    "Estos resultados indican que la regularización ha sido efectiva para reducir el overfitting que observamos previamente en el modelo de regresión logística sin regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c585b03239f62",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "901d9a43ed01a029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:01:42.260527Z",
     "start_time": "2023-08-28T01:01:42.196469400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: 0.787\n",
      "XGBoost: 0.973\n"
     ]
    }
   ],
   "source": [
    "# Haremos una prueba con un xgboost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, y_pred)\n",
    "training_accuracy = accuracy_score(y_train, xgb.predict(X_train))\n",
    "\n",
    "print('XGBoost: {:.3f}'.format(testing_accuracy))\n",
    "print('XGBoost: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a959184b2c5dba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Al probar un modelo de XGBoost en nuestros datos, observamos un accuracy del aproximadamente 97.3% en los datos de entrenamiento, mientras que en los datos de prueba obtenemos un accuracy de alrededor del 78.7%. Esta discrepancia significativa en el rendimiento entre entrenamiento y prueba indica una vez más la presencia de overfitting, donde el modelo está aprendiendo demasiado los detalles específicos de los datos de entrenamiento y tiene dificultades para generalizar a nuevos datos.\n",
    "\n",
    "Dado este desafío, nuestra estrategia para abordar el overfitting es utilizar Grid Search para optimizar los parámetros del modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78c88dfa13181507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:13:16.922629500Z",
     "start_time": "2023-08-28T01:11:27.010606700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5040 candidates, totalling 25200 fits\n",
      "{'alpha': 0.5, 'gamma': 0.5, 'lambda': 0.1, 'max_depth': 2, 'min_child_weight': 1}\n",
      "XGBoost: 0.758\n",
      "XGBoost: 0.884\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.2, 0.5, 1, 2, 10],             \n",
    "    'lambda': [0.05, 0.1, 0.2, 0.5, 1, 2, 10],            \n",
    "    'gamma': [0, 0.1, 0.5, 1],             \n",
    "    'max_depth': [1, 2, 3, 4, 5],\n",
    "    'min_child_weight': [1, 2, 5, 10, 15, 20]   \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=5,                     \n",
    "    verbose=1,            \n",
    "    n_jobs=-1        \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "best_clf = grid_search.best_estimator_\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, best_clf.predict(X_test))\n",
    "training_accuracy = accuracy_score(y_train, best_clf.predict(X_train))\n",
    "\n",
    "print('XGBoost: {:.3f}'.format(testing_accuracy))\n",
    "print('XGBoost: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8a05f581db3be",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Después de aplicar Grid Search para optimizar los parámetros en nuestro modelo XGBoost, observamos una mejora en el rendimiento. En los datos de prueba, ahora obtenemos un accuracy del aproximadamente 88.4%, en comparación con el 78.7% obtenido anteriormente sin la optimización de parámetros. En los datos de entrenamiento, el rendimiento también ha mejorado, alcanzando un accuracy de alrededor del 75.8%.\n",
    "\n",
    "A pesar de estas mejoras, todavía enfrentamos el desafío del overfitting. La discrepancia entre el rendimiento en entrenamiento y prueba indica que el modelo todavía tiene dificultades para generalizar completamente a nuevos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d43a31d21edb76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af20207c9e3f3ff2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-28T01:18:22.379947Z",
     "start_time": "2023-08-28T01:18:22.245355200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier: 0.764\n",
      "Voting Classifier: 0.879\n"
     ]
    }
   ],
   "source": [
    "# Se crea una pipeline para cada modelo\n",
    "\n",
    "# Random Forest a esta no se le aplica un scaler ya que al ser un modelo de arboles por steps todas las variables se reciben como independientes\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"rf\", RandomForestClassifier(bootstrap=True, criterion='entropy', max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50, random_state=42))\n",
    "])\n",
    "\n",
    "# Logistic Regression estamos utilizando los parametros obtenidos en las pruebas individuales de este modelo\n",
    "lr_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(penalty='elasticnet', C=1.0, solver='saga', l1_ratio=0.5, max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"xgb\", XGBClassifier(alpha=0.1, gamma=0.5, max_depth=2, min_child_weight=1, random_state=42))\n",
    "])\n",
    "\n",
    "# Se crea un Voting Classifier con los modelos anteriores\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    (\"rf\", rf_pipeline),\n",
    "    (\"lr\", lr_pipeline),\n",
    "    (\"xgb\", xgb_pipeline)\n",
    "], voting=\"soft\")\n",
    "\n",
    "# Se entrena el Voting Classifier\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "testing_accuracy = accuracy_score(y_test, y_pred)\n",
    "training_accuracy = accuracy_score(y_train, voting_classifier.predict(X_train))\n",
    "\n",
    "print('Voting Classifier: {:.3f}'.format(testing_accuracy))\n",
    "print('Voting Classifier: {:.3f}'.format(training_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a2aa73f733861",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Tras entrenar el Voting Classifier, hemos observado que este modelo presenta un nivel de overfitting superior al modelo de Logistic Regression sin regularización. Sin embargo, al analizar la estabilidad de los resultados, notamos que el modelo de Logistic Regression sin regularización exhibe cambios significativos en el rendimiento entre cada iteración si se permite que sea aleatorio. Esto sugiere una alta variabilidad en los resultados.\n",
    "\n",
    "En este contexto, hemos tomado la decisión de sacrificar un poco de overfitting en favor de obtener un modelo más estable y consistente. A pesar de que el Voting Classifier muestra un mayor overfitting, su rendimiento es más predecible y constante en comparación con el modelo de Logistic Regression. Esto es esencial, especialmente si planeamos implementar este modelo en un entorno de producción donde la estabilidad y la consistencia son fundamentales.\n",
    "\n",
    "En resumen, si bien el Voting Classifier tiene un mayor overfitting en comparación con el modelo de Logistic Regression, su estabilidad y consistencia en los resultados son atributos valiosos que respaldan la elección de este último como el modelo preferido para resolver nuestro problema de clasificación binaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3502ca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
